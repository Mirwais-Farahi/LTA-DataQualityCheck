{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPjWU457d87TF+zjbrd98/F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mirwais-Farahi/LTA-DataQualityCheck/blob/main/LTADataCollection_Tracker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QVCXKgfx0KsJ",
        "outputId": "4e90d6ed-a8e5-4702-8be4-916b3ae94482",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting koboextractor\n",
            "  Downloading koboextractor-0.2.1-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from koboextractor) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->koboextractor) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->koboextractor) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->koboextractor) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->koboextractor) (2024.8.30)\n",
            "Downloading koboextractor-0.2.1-py3-none-any.whl (9.1 kB)\n",
            "Installing collected packages: koboextractor\n",
            "Successfully installed koboextractor-0.2.1\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import data_table\n",
        "\n",
        "data_table.enable_dataframe_formatter()\n",
        "!pip install koboextractor\n",
        "!pip install openpyxl\n",
        "from koboextractor import KoboExtractor"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Take input from the user for KoBoToolbox API token and asset UID\n",
        "KOBO_TOKEN = input(\"Enter your KoBoToolbox API token: \")\n",
        "asset_uid = input(\"Enter the asset UID for the form: \")\n",
        "\n",
        "# Set up the KoBoToolbox API with the token and base URL\n",
        "kobo = KoboExtractor(KOBO_TOKEN, 'https://eu.kobotoolbox.org/api/v2')\n",
        "\n",
        "# Fetch data submitted after a specific date\n",
        "new_data = kobo.get_data(asset_uid, submitted_after='2024-10-06')\n",
        "\n",
        "# Convert the results directly into a DataFrame\n",
        "df = pd.DataFrame(new_data['results'])\n",
        "\n",
        "# Display the number of rows in the DataFrame\n",
        "print(f\"Number of records: {len(df)}\")"
      ],
      "metadata": {
        "id": "dzv6NDH-SjwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "YKypyzTb7DSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "row_count = df.shape[0]\n",
        "print(\"Number of rows in the DataFrame:\", row_count)"
      ],
      "metadata": {
        "id": "JxVjcpQggO5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set display options\n",
        "pd.set_option('display.max_rows', None)  # Display all rows\n",
        "pd.set_option('display.max_columns', None)  # Display all columns"
      ],
      "metadata": {
        "id": "Ha1vBKTin9DD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[[\"project_code\", \"assistance\"]].drop_duplicates()"
      ],
      "metadata": {
        "id": "NQGZcUzfPizs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize lists to hold project codes and intervention types\n",
        "project_codes_to_count = []\n",
        "intervention_types_to_count = []\n",
        "\n",
        "# Function to get user input and add to the lists\n",
        "def add_to_list():\n",
        "    print(\"Enter project codes. Type 'done' when finished:\")\n",
        "    while True:\n",
        "        project_code = input(\"Enter a project code (or 'done' to finish): \")\n",
        "        if project_code.lower() == 'done':\n",
        "            break\n",
        "        project_codes_to_count.append(project_code)\n",
        "        print(f\"Added project code '{project_code}' to the list.\")\n",
        "\n",
        "    print(\"Enter intervention types. Type 'done' when finished:\")\n",
        "    while True:\n",
        "        intervention_type = input(\"Enter an intervention type (or 'done' to finish): \")\n",
        "        if intervention_type.lower() == 'done':\n",
        "            break\n",
        "        intervention_types_to_count.append(intervention_type)\n",
        "        print(f\"Added intervention type '{intervention_type}' to the list.\")\n",
        "\n",
        "# Get user input\n",
        "add_to_list()\n",
        "\n",
        "# Filter the DataFrame by the specified project codes and intervention types\n",
        "filtered_df = df[(df['project_code'].isin(project_codes_to_count)) & (df['assistance'].isin(intervention_types_to_count))]\n",
        "\n",
        "# Group by Province and District and count the number of surveys in each district\n",
        "result = filtered_df.groupby(['province', 'district']).size().reset_index(name='Total Surveys in District')\n",
        "\n",
        "# Display the result\n",
        "result"
      ],
      "metadata": {
        "id": "OFpueIvrAxja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filtered_df = filtered_df.dropna(axis=1, how='all')\n",
        "filtered_df.head()"
      ],
      "metadata": {
        "id": "2Hrmjh6A3jIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Ask the user for the column name\n",
        "column_name = input(\"Enter the column name to plot: \")\n",
        "\n",
        "# Convert the column to numeric, forcing errors to NaN\n",
        "filtered_df[column_name] = pd.to_numeric(filtered_df[column_name], errors='coerce')\n",
        "\n",
        "# Drop rows with NaN values in the column\n",
        "numeric_df = filtered_df.dropna(subset=[column_name])\n",
        "\n",
        "# Define the column of interest\n",
        "numeric_columns = [column_name]\n",
        "\n",
        "# Draw the box plot\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "# Create the box plot with improved readability\n",
        "box = plt.boxplot(numeric_df[numeric_columns].values, vert=False, patch_artist=True, labels=numeric_columns)\n",
        "\n",
        "# Customize the box plot\n",
        "plt.title(f'Box Plot for {column_name}', fontsize=16)\n",
        "plt.xlabel(f'Number of {column_name}', fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Set colors for the box plot elements\n",
        "colors = ['#FF9999']\n",
        "for patch, color in zip(box['boxes'], colors):\n",
        "    patch.set_facecolor(color)\n",
        "\n",
        "# Customize whiskers and medians\n",
        "for whisker in box['whiskers']:\n",
        "    whisker.set(color='#7570b3', linewidth=2)\n",
        "for cap in box['caps']:\n",
        "    cap.set(color='#7570b3', linewidth=2)\n",
        "for median in box['medians']:\n",
        "    median.set(color='orange', linewidth=2)\n",
        "for flier in box['fliers']:\n",
        "    flier.set(marker='o', color='#e7298a', alpha=0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QTi9DqdZz0KB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe method\n",
        "description = numeric_df[column_name].describe()\n",
        "print(f\"Descriptive statistics for '{column_name}':\")\n",
        "print(f\"  - Number of entries: {description['count']}\")\n",
        "print(f\"  - Average value: {description['mean']}\")\n",
        "print(f\"  - Standard deviation: {description['std']}\")\n",
        "print(f\"  - Minimum value: {description['min']}\")\n",
        "print(f\"  - 25th percentile (25% of values are below this): {description['25%']}\")\n",
        "print(f\"  - Median (50% of values are below this): {description['50%']}\")\n",
        "print(f\"  - 75th percentile (75% of values are below this): {description['75%']}\")\n",
        "print(f\"  - Maximum value: {description['max']}\")\n",
        "\n",
        "# Percentile calculation\n",
        "percentiles = [0.9, 0.99]  # 90th and 99th percentiles\n",
        "percentile_values = numeric_df[column_name].quantile(percentiles)\n",
        "print(f\"\\n90th Percentiles for '{column_name}':\")\n",
        "print(f\"  - 90th percentile (90% of values are below this): {percentile_values[0.9]}\")\n",
        "print(f\"  - 99th percentile (99% of values are below this): {percentile_values[0.99]}\")\n"
      ],
      "metadata": {
        "id": "g7_a1-F7b74y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_df[column_name].hist()\n",
        "plt.xlabel(f'{column_name} Values Distribution')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title(f'Histogram')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wxCy-7ZHVXCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the IQR for outlier detection\n",
        "Q1 = filtered_df[numeric_columns[0]].quantile(0.25)\n",
        "Q3 = filtered_df[numeric_columns[0]].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Define outlier boundaries\n",
        "lower_bound = Q1 - 1.5 * IQR\n",
        "upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "# Detect outliers\n",
        "outliers_df = filtered_df[(filtered_df[numeric_columns[0]] < lower_bound) | (filtered_df[numeric_columns[0]] > upper_bound)]\n",
        "\n",
        "print(f'Outliers Len: {len(outliers_df)}')"
      ],
      "metadata": {
        "id": "_A9w9kHB3y_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the index of the specific column\n",
        "col_index = outliers_df.columns.get_loc(column_name)\n",
        "\n",
        "# Select columns from 0 to the specific column\n",
        "selected_columns_outliers_df = outliers_df.iloc[:, :col_index + 1]\n",
        "\n",
        "selected_columns_outliers_df"
      ],
      "metadata": {
        "id": "GwHd6cYiesBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "# Get current date and time\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "# Define the file path with date and time\n",
        "file_name = f\"outliers_{column_name}_{current_time}.xlsx\"\n",
        "\n",
        "# Write DataFrame to an Excel file\n",
        "selected_columns_outliers_df.to_excel(file_name, index=False)\n",
        "\n",
        "# Automatically download the file to the local machine\n",
        "files.download(file_name)\n",
        "\n",
        "print(f\"Data successfully saved and download initiated for {file_name}\")"
      ],
      "metadata": {
        "id": "HGhbZfnLeCaJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'start' and 'end' columns to datetime with error handling\n",
        "try:\n",
        "    filtered_df['start'] = pd.to_datetime(filtered_df['start'], errors='coerce')\n",
        "    filtered_df['end'] = pd.to_datetime(filtered_df['end'], errors='coerce')\n",
        "except Exception as e:\n",
        "    print(f\"Error converting to datetime: {e}\")\n",
        "\n",
        "# Calculate the duration in minutes, handling NaT values\n",
        "filtered_df['duration'] = (filtered_df['end'] - filtered_df['start']).dt.total_seconds() / 60\n",
        "\n",
        "# Get minimum and maximum duration from the user\n",
        "try:\n",
        "    min_duration = float(input(\"Enter the minimum duration in minutes: \"))\n",
        "    max_duration = float(input(\"Enter the maximum duration in minutes: \"))\n",
        "except ValueError as e:\n",
        "    print(f\"Invalid input: {e}\")\n",
        "    min_duration = 0\n",
        "    max_duration = float('inf')\n",
        "\n",
        "# Find surveys that took between min_duration and max_duration minutes\n",
        "surveys_with_less_time_df = filtered_df[\n",
        "    (filtered_df['duration'] > min_duration) & (filtered_df['duration'] < max_duration)\n",
        "]\n",
        "\n",
        "print(f'Number of Surveys with less than {min_duration} and more than {max_duration}:', len(surveys_with_less_time_df))"
      ],
      "metadata": {
        "id": "f9nmORvhSrqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the index of the specific column\n",
        "col_index = filtered_df.columns.get_loc('duration')\n",
        "\n",
        "# Get the list of columns to select\n",
        "cols_to_select = list(filtered_df.columns[:18])  # First 10 columns\n",
        "if 'duration' not in cols_to_select:\n",
        "    cols_to_select.append('duration')  # Add 'duration' if it's not already in the list\n",
        "\n",
        "# Select columns from the DataFrame\n",
        "selected_surveys_with_less_time_df = filtered_df[cols_to_select]\n",
        "\n",
        "# Display the DataFrame with selected columns\n",
        "selected_surveys_with_less_time_df"
      ],
      "metadata": {
        "id": "evpI0Mo0omkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "\n",
        "# Convert object type columns that should be datetimes\n",
        "for col in surveys_with_less_time_df.columns:\n",
        "    if surveys_with_less_time_df[col].dtype == 'object':\n",
        "        try:\n",
        "            # Attempt to convert the column to datetime\n",
        "            surveys_with_less_time_df[col] = pd.to_datetime(surveys_with_less_time_df[col], errors='coerce')\n",
        "        except Exception as e:\n",
        "            print(f\"Error converting column '{col}' to datetime: {e}\")\n",
        "\n",
        "# Convert timezone-aware datetime columns to timezone-naive\n",
        "def convert_to_naive(df):\n",
        "    for col in df.select_dtypes(include=['datetime64[ns, UTC]']).columns:\n",
        "        if df[col].dt.tz is not None:\n",
        "            df[col] = df[col].dt.tz_localize(None)\n",
        "    return df\n",
        "\n",
        "# Convert timezone-aware datetime columns to timezone-naive\n",
        "surveys_with_less_time_df = convert_to_naive(surveys_with_less_time_df)\n",
        "\n",
        "# Get current date and time\n",
        "current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "\n",
        "# Define the file path with date and time\n",
        "file_name = f\"surveys_collected_moreThan_{min_duration}_lessThan_{max_duration}_{current_time}.xlsx\"\n",
        "\n",
        "# Write DataFrame to an Excel file\n",
        "surveys_with_less_time_df.to_excel(file_name, index=False)\n",
        "\n",
        "# Automatically download the file to the local machine\n",
        "files.download(file_name)\n",
        "\n",
        "print(f\"Data successfully saved and download initiated for {file_name}\")"
      ],
      "metadata": {
        "id": "tHhJVJ6fiGLC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}